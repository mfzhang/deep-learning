取weight的方式可以省略掉赋值的过程
求cblas函数时，过多的变量，将这些删掉，直接填入m，n，k，alpha，beta
可以去掉dw2，直接在blas函数里面将c的系数变为1
pooling开始会增加是因为w在改变，w部分值开始变大
问题是，hidden层数据没有减小到很小
当删除掉pooling的影响，仍然出现w改变很明显，前后cost差异较大的情况,并且w仍然不对，说明是r的问题


10月24日
将读写文件的地方做了改进，假如打不开则报错和返回
将代码长度整理
将某些地方计算量减少

10月25日
仍然减少计算量

10月27日
计算变快，问题仍未找出，看完cuda编程第六课

10月29日
cpu调不出来，准备开始写gpu
1.输入预处理，unsigned char
2.初始化w，设置种子，随机数起始值
3.计算w*x，得到h，同时得到r，一次计算一个minibatch
4.计算p
5.计算lcn

书上例子都是关于单机，多机用
完成了矩阵相乘

10月30日
发现cudaSgemm是host上的函数不能用在kernel中,int i以后可以改成unsigned int i
人脸变成灰度图并预处理

10月31日
改变代码风格，将代码变得紧凑一些
只用reconstruct是无法学到特征的
代码调粗来了！
查看关于face detection的论文，考虑是否能做同样的事情

11月1日
用自己的程序跑人脸

11月4日
整理本次实验相关



